{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJbcVQKZPuh0RWBY/zvKbl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kateriiina/Lesson/blob/main/%D0%97%D0%B0%D0%B4%D0%B0%D1%87%D0%B0_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_DYCn61pOaGo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Задані дані\n",
        "input_data = np.array([[0.1, 0.9]])\n",
        "target_output = np.array([[0.9]])\n",
        "\n",
        "# Вагові коефіцієнти\n",
        "weights_layer1 = np.array([[0.1, 0.1, -0.2], [-0.1, 0.1, 0.3]])\n",
        "weights_layer2 = np.array([[0.2], [0.2], [0.3]])\n",
        "\n",
        "# Швидкість навчання\n",
        "learning_rate = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Перший шар\n",
        "hidden_layer_input = np.dot(input_layer, weights_layer1)\n",
        "print(f\"Вагові суми для прихованого шару (перший шар): {hidden_layer_input}\")\n",
        "hidden_layer_output = sigmoid(hidden_layer_input)\n",
        "print(f\"Вихід прихованого шару (після активації): {hidden_layer_output}\")\n",
        "\n",
        "# Другий шар\n",
        "output_layer_input = np.dot(hidden_layer_output, weights_layer2)\n",
        "print(f\"Вагові суми для вихідного шару (другий шар): {output_layer_input}\")\n",
        "predicted_output = sigmoid(output_layer_input)\n",
        "print(f\"Вихід вихідного шару (після активації): {predicted_output}\")\n",
        "\n",
        "# Зворотній прохід (Backpropagation)\n",
        "output_error = target_output - predicted_output\n",
        "output_delta = output_error * sigmoid_derivative(predicted_output)\n",
        "\n",
        "hidden_layer_error = output_delta.dot(weights_layer2.T)\n",
        "hidden_delta = hidden_layer_error * sigmoid_derivative(hidden_layer_output)\n",
        "\n",
        "# Оновлення вагових коефіцієнтів\n",
        "weights_layer2 += learning_rate * hidden_layer_output.T.dot(output_delta)\n",
        "weights_layer1 += learning_rate * input_layer.T.dot(hidden_delta)\n",
        "\n",
        "# Вивід результатів після зворотного проходу\n",
        "print(\"\\nЗворотний прохід:\")\n",
        "print(f\"Помилка вихідного шару: {output_error}\")\n",
        "print(f\"Градієнт вихідного шару: {output_delta}\")\n",
        "print(f\"Помилка прихованого шару: {hidden_layer_error}\")\n",
        "print(f\"Градієнт прихованого шару: {hidden_delta}\")\n",
        "\n",
        "print(\"\\nНові вагові коефіцієнти:\")\n",
        "print(\"Для другого шару:\\n\", weights_layer2)\n",
        "print(\"Для першого шару:\\n\", weights_layer1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXIv4XgyO3hB",
        "outputId": "b0ba5bf5-7a44-4b10-dfda-cd13d6e06b71"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Вагові суми для прихованого шару (перший шар): [[-0.0790734   0.10092726  0.25136525]]\n",
            "Вихід прихованого шару (після активації): [[0.48024194 0.52521042 0.56251251]]\n",
            "Вагові суми для вихідного шару (другий шар): [[0.38813938]]\n",
            "Вихід вихідного шару (після активації): [[0.59583471]]\n",
            "\n",
            "Зворотний прохід:\n",
            "Помилка вихідного шару: [[0.30416529]]\n",
            "Градієнт вихідного шару: [[0.07324778]]\n",
            "Помилка прихованого шару: [[0.01543164 0.0155049  0.02289033]]\n",
            "Градієнт прихованого шару: [[0.00385189 0.00386637 0.00563313]]\n",
            "\n",
            "Нові вагові коефіцієнти:\n",
            "Для другого шару:\n",
            " [[0.2141949 ]\n",
            " [0.21552439]\n",
            " [0.31662567]]\n",
            "Для першого шару:\n",
            " [[ 0.10015152  0.10015174 -0.19977717]\n",
            " [-0.09863633  0.1013657   0.30200543]]\n"
          ]
        }
      ]
    }
  ]
}